{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "a126c76d-17e0-408e-a3c8-9a38226c894f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bbe191c6",
    "execution_start": 1654134745093,
    "execution_millis": 348,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "!cd ../yolov3 && git checkout .",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import sys\nsys.path.append(\"../yolov3\")",
   "metadata": {
    "cell_id": "74c1ebc416534453bf5c82dbe7f29b36",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "97ac1e63",
    "execution_start": 1654134745449,
    "execution_millis": 7,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import train\ntrain.run(data='coco128.yaml', cfg='yolov3-tiny.yaml', weights='', device='cpu', \nbatch_size=3, epochs=1, noval=True, project='/datasets/train', name='exp')",
   "metadata": {
    "cell_id": "823213110fba4eb29f03d862eee4cf66",
    "tags": [],
    "owner_user_id": "64653946-af2f-4699-a282-4043b0ba5576",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8c3d4e3f",
    "execution_start": 1654134745463,
    "execution_millis": 443977,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 787,
    "deepnote_output_heights": [
     21.1875
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=yolov3-tiny.yaml, data=coco128.yaml, hyp=../yolov3/data/hyps/hyp.scratch.yaml, epochs=1, batch_size=3, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=/datasets/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\nYOLOv3 ðŸš€ v9.6.0-17-g3508a98 torch 1.11.0+cu102 CPU\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /datasets/train', view at http://localhost:6006/\n\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 ðŸš€ runs (RECOMMENDED)\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1       464  models.common.Conv                      [3, 16, 3, 1]                 \n  1                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n  2                -1  1      4672  models.common.Conv                      [16, 32, 3, 1]                \n  3                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n  4                -1  1     18560  models.common.Conv                      [32, 64, 3, 1]                \n  5                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n  6                -1  1     73984  models.common.Conv                      [64, 128, 3, 1]               \n  7                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n  8                -1  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n  9                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n 10                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n 11                -1  1         0  torch.nn.modules.padding.ZeroPad2d      [[0, 1, 0, 1]]                \n 12                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 1, 0]                     \n 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n 14                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n 15                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n 16                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n 19                -1  1    885248  models.common.Conv                      [384, 256, 3, 1]              \n 20          [19, 15]  1    196350  models.yolo.Detect                      [80, [[10, 14, 23, 27, 37, 58], [81, 82, 135, 169, 344, 319]], [256, 512]]\nModel Summary: 59 layers, 8852366 parameters, 8852366 gradients\n\nScaled weight_decay = 0.0004921875\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 11 weight, 13 weight (no decay), 13 bias\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\nPlotting labels to /datasets/train/exp2/labels.jpg... \n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.86 anchors/target, 0.988 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/datasets/train/exp2\u001b[0m\nStarting training for 1 epochs...\n\n     Epoch   gpu_mem       box       obj       cls    labels  img_size\n  0%|          | 0/43 [00:00<?, ?it/s]                                          /shared-libs/python3.9/py/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n       0/0        0G    0.1203      0.21    0.1043        44       640:   2%|â–  /shared-libs/python3.9/py/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n       0/0        0G    0.1173     0.182    0.1047        23       640: 100%|â–ˆâ–ˆâ–ˆ\n               Class     Images     Labels          P          R     mAP@.5 mAP@\n                 all        128          0          0          0          0          0\n\n1 epochs completed in 0.086 hours.\n\nValidating /datasets/train/exp2/weights/best.pt...\nFusing layers... \nOptimizer stripped from /datasets/train/exp2/weights/last.pt, 17.8MB\nOptimizer stripped from /datasets/train/exp2/weights/best.pt, 17.8MB\nModel Summary: 48 layers, 8849182 parameters, 0 gradients\n               Class     Images     Labels          P          R     mAP@.5 mAP@\n                 all        128          0          0          0          0          0\nResults saved to \u001b[1m/datasets/train/exp2\u001b[0m\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=4c27263b-a773-4b36-bc5c-6cb959f3ea6f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {},
  "deepnote_notebook_id": "abc29c71-1762-4437-b3aa-1cc083cb3cea",
  "deepnote_execution_queue": []
 }
}